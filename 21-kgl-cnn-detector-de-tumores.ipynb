{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**IMPORTACIÓN DE LIBRERIAS**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout #RN convulocional\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:30.365000Z","iopub.execute_input":"2025-10-27T22:52:30.365446Z","iopub.status.idle":"2025-10-27T22:52:30.372911Z","shell.execute_reply.started":"2025-10-27T22:52:30.365420Z","shell.execute_reply":"2025-10-27T22:52:30.371008Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"**CONFIGURAR RUTA DEL DATASET**","metadata":{}},{"cell_type":"code","source":"# Ruta del dataset descargando desde la sección 'add dataset' en kaggle notebook\ndataset_path =\"/kaggle/input/brain-tumor-mri-dataset\"\n\n# Verificamos las carpetas del dataset \nos.listdir(dataset_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:30.949935Z","iopub.execute_input":"2025-10-27T22:52:30.950363Z","iopub.status.idle":"2025-10-27T22:52:30.958177Z","shell.execute_reply.started":"2025-10-27T22:52:30.950332Z","shell.execute_reply":"2025-10-27T22:52:30.957107Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['Training', 'Testing']"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"**PARAMETROS DE PREPROCESAMIENTO**","metadata":{}},{"cell_type":"code","source":"# Dimensiones de las imagenes (todos seran redimensionados)\nimg_width = 150\nimg_height = 150\n\n# Definir rutas especificas\ntrain_dir = os.path.join(dataset_path, 'Training')\ntest_dir = os.path.join(dataset_path, 'Testing')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:33.211365Z","iopub.execute_input":"2025-10-27T22:52:33.211708Z","iopub.status.idle":"2025-10-27T22:52:33.217782Z","shell.execute_reply.started":"2025-10-27T22:52:33.211685Z","shell.execute_reply":"2025-10-27T22:52:33.216497Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"**AUMENTACIÓN DE DATOS**","metadata":{}},{"cell_type":"code","source":"# Generador de imagenes de entrenamiento\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,       #Normalizar\n    rotation_range=20,   #Rotar Ligeramente\n    zoom_range=0.15,     #Zoom Aleatorio\n    width_shift_range=0.2,  #Desplazamiento Horizontal\n    height_shift_range=0.2, #Desplazamiento Vertical\n    shear_range=0.15,    #Cizalladura\n    horizontal_flip=True,   #Volteo Horizontal\n    fill_mode=\"nearest\"     #Relleno de pixeles vacios\n)\n\n# Generador de imagenes de prueba (solo normalizar)\ntest_datagen = ImageDataGenerator(rescale=1/255)\n\n# Crear datasets\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_width, img_height),\n    batch_size=32,\n    class_mode='binary'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_width, img_height),\n    batch_size=32,\n    class_mode='binary'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:35.072651Z","iopub.execute_input":"2025-10-27T22:52:35.072950Z","iopub.status.idle":"2025-10-27T22:52:35.938438Z","shell.execute_reply.started":"2025-10-27T22:52:35.072931Z","shell.execute_reply":"2025-10-27T22:52:35.937256Z"}},"outputs":[{"name":"stdout","text":"Found 5712 images belonging to 4 classes.\nFound 5712 images belonging to 4 classes.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"**CREAR EL MODELO CNN**","metadata":{}},{"cell_type":"code","source":"model = Sequential ([\n    Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n    MaxPooling2D(2,2),\n\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid') #Salida: Tumor o no Tumor solo 2 estados\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:39.132338Z","iopub.execute_input":"2025-10-27T22:52:39.132652Z","iopub.status.idle":"2025-10-27T22:52:39.291724Z","shell.execute_reply.started":"2025-10-27T22:52:39.132630Z","shell.execute_reply":"2025-10-27T22:52:39.290590Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**COMPILAR MODELO**","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:43.545548Z","iopub.execute_input":"2025-10-27T22:52:43.545898Z","iopub.status.idle":"2025-10-27T22:52:43.567053Z","shell.execute_reply.started":"2025-10-27T22:52:43.545875Z","shell.execute_reply":"2025-10-27T22:52:43.566127Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"**ENTRENAMIENTO DEL MODELO**","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=15,\n    validation_data=test_generator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T22:52:45.345925Z","iopub.execute_input":"2025-10-27T22:52:45.346915Z","execution_failed":"2025-10-28T02:36:50.422Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 1s/step - accuracy: 0.2211 - loss: -137694704.0000 - val_accuracy: 0.2344 - val_loss: -8730300416.0000\nEpoch 2/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - accuracy: 0.2379 - loss: -50360229888.0000 - val_accuracy: 0.2344 - val_loss: -582918668288.0000\nEpoch 3/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.2309 - loss: -1141583773696.0000 - val_accuracy: 0.2344 - val_loss: -5549402882048.0000\nEpoch 4/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.2323 - loss: -8201747038208.0000 - val_accuracy: 0.2344 - val_loss: -25131296489472.0000\nEpoch 5/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 1s/step - accuracy: 0.2397 - loss: -30605433634816.0000 - val_accuracy: 0.2344 - val_loss: -77368039309312.0000\nEpoch 6/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.2291 - loss: -88815024734208.0000 - val_accuracy: 0.2344 - val_loss: -189273621921792.0000\nEpoch 7/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 1s/step - accuracy: 0.2412 - loss: -207281312497664.0000 - val_accuracy: 0.2344 - val_loss: -393191270383616.0000\nEpoch 8/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1s/step - accuracy: 0.2328 - loss: -431837956538368.0000 - val_accuracy: 0.2344 - val_loss: -727262852808704.0000\nEpoch 9/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 1s/step - accuracy: 0.2471 - loss: -721345595834368.0000 - val_accuracy: 0.2344 - val_loss: -1241203806830592.0000\nEpoch 10/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.2490 - loss: -1213146664534016.0000 - val_accuracy: 0.2344 - val_loss: -1985416815181824.0000\nEpoch 11/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.2424 - loss: -1890414420295680.0000 - val_accuracy: 0.2344 - val_loss: -3031717556256768.0000\nEpoch 12/15\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853ms/step - accuracy: 0.2392 - loss: -2873293929447424.0000","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"**GRAFICAR PRECISIÓN Y PERDIDA**","metadata":{}},{"cell_type":"code","source":"# Precisión\nplt.plot(history.history['accuracy'], label='Precisión Entrenamiento')\nplt.plot(history.history['val_accuracy'], label='Precisión Validación')\nplt.title('Precisión durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Precisión')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Pérdida\nplt.plot(history.history['loss'], label='Pérdida Entrenamiento')\nplt.plot(history.history['val_loss'], label='Pérdida Validación')\nplt.title('Pérdida durante el entrenamiento')\nplt.xlabel('Épocas')\nplt.ylabel('Pérdida')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**PREDICCIÓN DE UNA SOLA IMAGEN**","metadata":{}},{"cell_type":"code","source":"# Ruta de una imagen de prueba \ntest_image_path = os.path.join(test_dir, 'notumor', 'Te-no_0010.jpg') # Puedes cambiar la subcarpeta\n\n# Cargar Imagen\nimg = cv2.imread(test_image_path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Convertir BGR a RGB\nimg_resized = cv2.resize(img, (img_width, img_height))\n\n# Normalizar y expandir dimensiones\nimg_normalized = img_resized / 255.0\nimg_input = np.expand_dims(img_normalized, axis=0) # (1, 150, 150,3)\n\n# Realizar predicción\nprediction = model.predict(img_input)[0][0]\n\n# Interpretar Predicción\nif prediction > 0.5:\n    resultado = \"Tumor detectado\"\n    color = \"red\"\nelse:\n    resultado = \"No se detecto tumor\"\n    color = \"green\"\n\n# Mostrar Imagen y Resultado\nplt.figure(figsize=(5,5))\nplt.imshow(img.resized)\nplt.title(f\"{resultado} ({prediction:.2f})\", color=color)\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}